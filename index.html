<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="description" content="Sync from the Sea: Retrieving Alignable Videos from Large-Scale Datasets">
    <title>Sync from the Sea: Retrieving Alignable Videos from Large-Scale Datasets</title>
  
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag('js', new Date());
      gtag('config', 'G-PYVRSFMDRL');
    </script>
  
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">
  
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    <style>
      .item video {
        width: 100%; /* ensures video fills the container width */
        height: 500px; /* fixed height, change this value as needed */
      }
    </style>
  </head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Sync from the Sea: Retrieving Alignable Videos from Large-Scale Datasets</h1> <br>          
          <h1 class="title is-1 publication-title">ECCV 2024 <font color="Chestnut Red">(Oral Presentation) </font> </h1> <br>

          <!-- <h1 class="title is-1 publication-title">Under Construction (Stay tuned!)</h1> -->

          <div class="is-size-5 publication-authors"> 
            <span class="author-block">
              <a href="https://daveishan.github.io/">Ishan Dave<sup>1*</sup></a>,</span>
            <span class="author-block">
              <a href="https://fabiancaba.com/">Fabian Caba<sup>2</sup></a>,</span>
            <span class="author-block">
              <a href="https://www.crcv.ucf.edu/person/mubarak-shah/">Mubarak Shah<sup>1</sup>,</a>
            </span>
            <span class="author-block">
              <a href="https://sjenni.github.io/">Simon Jenni<sup>2</sup></a></span>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Central Florida, <sup>2</sup>Adobe Research</span><br>
            <span class="author-block" style="font-size: 0.5em;"><sup>*</sup> Work done as an intern at Adobe Research, USA.</span>

          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              
              <span class="link-block">
                <a href="https://www.crcv.ucf.edu/wp-content/uploads/2018/11/avr_eccv24_dave.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>PrePrint</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>

              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-image"></i>
                  </span>
                  <span>Poster</span>
                </a>
              </span>
              
            </div>
            


            

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
  <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
  <!--       <div class="column is-four-fifths"> -->
      <!-- <div class="column is-full"> Changed to is-full for full width -->
      <div class="column is-four-fifths">

       <h3 class="title is-3">TL;DR:</h3>
            <div class="content has-text-justified">
                <p>
                  <!-- Our contribution is as follows:
                    <ul>
                        <li>AAAAAAA</li>
                        <li>AAAAAAA.</li>
                         Put image of the figure1

                        
                    </ul>
                     -->
                        <table style="width: 100%;">
                          <tr>
                              <!-- First subfigure -->
                              <td style="width: 39%; vertical-align: middle; text-align: center;">
                                  <img src="static/images/reg_temporal_alignment.drawio-1.png" style="width: 100%;">
                                  <p style="text-align: justify;">
                                      <strong>Regular Temporal Alignment:</strong> A pair of videos from the same action class is given. The goal is to align them, i.e., match their key-event frames.
                                  </p>
                              </td>
                              <!-- Second subfigure -->
                              <td style="width: 58%; vertical-align: middle; text-align: center;">
                                  <img src="static/images/avr_teaserV2.drawio-1.png" style="width: 100%;">
                                  <p style="text-align: justify;">
                                      <strong>Proposed Alignable Video Retrieval (AVR):</strong> Given a query video, the goal is to find the best alignable video from candidate videos of the video search results.
                                  </p>
                              </td>
                          </tr>
                      </table>
                      <p style="text-align: justify;">
                          <strong>Alignable Video Retrieval.</strong> While some actions, like "baseball swing" (left), permit temporal alignment in virtually all cases due to their fixed sequence of action phases, general videos from other action classes, like "cutting pineapple" (right), exhibit much more variability. Knowledge of the action category alone is insufficient to identify alignable pairs for these cases, and a deeper temporal understanding of the videos is required to identify alignable videos. We propose DRAQ, an alignability score that can reliably identify the alignable video pair (red) among the set of candidates.
                      </p>
                      
                      

                    
                </p>
            </div>
            

          
      </div>
    </div>

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Temporal video alignment aims to synchronize the key events like object interactions or action phase transitions in two videos. Such methods could benefit various video editing, processing, and understanding tasks. However, existing approaches operate under the restrictive assumption that a suitable video pair for alignment is given, significantly limiting their broader applicability. To address this, we re-pose temporal alignment as a search problem and introduce the task of Alignable Video Retrieval (AVR). Given a query video, our approach can identify well-alignable videos from a large collection of clips and temporally synchronize them to the query. To achieve this, we make three key contributions: 1) we introduce DRAQ, a video alignability indicator to identify and re-rank the best alignable video from a set of candidates; 2) we propose an effective and generalizable frame-level video feature design to improve the alignment performance of several off-the-shelf feature representations, and 3) we propose a novel benchmark and evaluation protocol for AVR using cycle-consistency metrics. Our experiments on 3 datasets, including large-scale Kinetics700, demonstrate the effectiveness of our approach in identifying alignable video pairs from diverse datasets.
          </p>
        </div>
      </div>
    </div>

    <section class="section" id="Method">
      <div class="container is-max-desktop content">
        <h2 class="title">Method</h2>
        <div style="width: 100%; text-align: center;">
          <img src="static/images/system_figure_avr.drawio-1.png" style="width: 100%;">
          <p style="text-align: justify; margin-top: 20px;">
              <strong>Model Overview.</strong> We introduce a model for Aligned Video Retrieval (AVR): Given an input query video clip, our model aims to find and temporally align the best matching video among a large collection of videos. Our approach has three stages: 1) candidate retrieval from a large-scale database, 2) re-ranking of the top candidates to identify the most alignable clip using our procedure DRAQ, and 3) alignment of query and top match using DTW on our contextualized frame-level features.
          </p>
      </div>
      </div>
    </section>

<section class="section" id="Quantitative">
  <div class="container is-max-desktop content">
    <h2 class="title">Cyclic-consistency based AVR protocols</h2>
    <div class="container is-max-desktop content">
      
      <div style="width: 100%; text-align: center;">
        <img src="static/images/cycle_eval-1.png" style="width: 60%;">
        <p style="text-align: justify; margin-top: 20px;">
            <strong>AVR evaluation via Cycle-Consistency.</strong> We illustrate the use of consistency errors to measure aligned video retrieval performance. A query video (bottom left), along with phase labels (colored regions) and frame indices (below the video), is warped to the top retrieval video (top). 
            The aligned labels and frame indices are then warped back to the query again to complete the cycle. We then report the Frame Position Error (FPE) and the Cycle Phase Error (CPE) when the query contains phase information. 
        </p>
    </div>
    </div> 
    
    
    <br>
  </div>
</section>
    

<section class="section" id="Qualitative">
  <div class="container is-max-desktop content">
    <h2 class="title">Qualitative Results</h2>
    Top = Query video, Bottom: Retrieved Alignable video

    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <!-- Dynamic carousel items will be added here -->
      </div>
    </div>
  
    <script>
      document.addEventListener('DOMContentLoaded', function() {
        const carouselContainer = document.getElementById('results-carousel');
        const totalVideos = 20; // Total number of videos
  
        // Dynamically create video elements
        for (let i = 1; i <= totalVideos; i++) {
          const itemDiv = document.createElement('div');
          itemDiv.className = 'item';
          itemDiv.innerHTML = `
            <video poster="" controls muted loop playsinline height="100%">
              <source src="./static/videos/${i}.mp4" type="video/mp4">
            </video>
          `;
          carouselContainer.appendChild(itemDiv);
        }
  
        let currentIndex = 0;
        const items = document.querySelectorAll('.item');
  
        function showVideo(index) {
          items.forEach(item => item.classList.remove('active'));
          items[index].classList.add('active');
          items[index].querySelector('video').play();
        }
  
        function nextVideo() {
          currentIndex = (currentIndex + 1) % items.length;
          showVideo(currentIndex);
        }
  
        items.forEach((item, index) => {
          item.querySelector('video').addEventListener('ended', nextVideo);
        });
  
        // Initial display of the first video
        showVideo(0);
      });
    </script>
    
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @inproceedings{dave2024sync,
        title={Sync from the Sea: Retrieving Alignable Videos from Large-Scale Datasets},
        author={Dave, Ishan and Caba, Fabian and Shah, Mubarak and Jenni, Simon},
        booktitle={European Conference on Computer Vision (ECCV)},
        year={2024}
      }
    </code></pre>
  </div>
</section>
</body>
</html>
